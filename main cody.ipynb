{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c10670f5-3e4b-4ede-a4f0-92e3444ac2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f67dfe34-a259-4830-87b5-851c0bbfba13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset path found: C:/Users/user/anaconda3/envs/flower-ai-fixed/flowers-dataset\n",
      "âœ… Train Dataset: 1200 images in 3 classes\n",
      "âœ… Validation Dataset: 2532 images\n",
      "âœ… Test Dataset: 292 images\n",
      "ğŸ“ Classes: ['fresh daisy', 'fresh rose', 'fresh tulip']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# Define the dataset path\n",
    "dataset_path = \"C:/Users/user/anaconda3/envs/flower-ai-fixed/flowers-dataset\"\n",
    "\n",
    "# Check if the path exists\n",
    "if not os.path.exists(dataset_path):\n",
    "    raise FileNotFoundError(f\"âŒ Dataset path does not exist: {dataset_path}\")\n",
    "else:\n",
    "    print(f\"âœ… Dataset path found: {dataset_path}\")\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to fit model input\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = ImageFolder(root=f\"{dataset_path}/train\", transform=transform)\n",
    "val_dataset = ImageFolder(root=f\"{dataset_path}/validation\", transform=transform)\n",
    "test_dataset = ImageFolder(root=f\"{dataset_path}/test\", transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Check dataset details\n",
    "print(f\"âœ… Train Dataset: {len(train_dataset)} images in {len(train_dataset.classes)} classes\")\n",
    "print(f\"âœ… Validation Dataset: {len(val_dataset)} images\")import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Using Adam optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()  # Loss function\n",
    "\n",
    "print(f\"âœ… Test Dataset: {len(test_dataset)} images\")\n",
    "print(f\"ğŸ“ Classes: {train_dataset.classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05b49d29-fe6d-45a0-a7db-1a87631e40f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Using Device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\flower-ai-fixed\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\envs\\flower-ai-fixed\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\user/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"âœ… Using Device: {device}\")\n",
    "\n",
    "# Load the pre-trained ResNet18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all layers except the final layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers\n",
    "\n",
    "# Modify the final layer for 3 classes (daisy, rose, tulip)\n",
    "num_classes = 3\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09039efe-d736-4b74-b85b-71b03a6dfb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Using Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "\n",
    "# Define training parameters\n",
    "num_epochs = 10  # Adjust as needed\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"âœ… Using Device: {device}\")\n",
    "\n",
    "# Load ResNet model\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 3)  # 3 classes: daisy, rose, tulip\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# DataLoader setup\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100. * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "    \n",
    "print(\"âœ… Training Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d67a236-e840-4653-8553-49e4d551655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "import os\n",
    "\n",
    "# âœ… Check for device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"âœ… Using Device: {device}\")\n",
    "\n",
    "# âœ… Define dataset paths\n",
    "dataset_path = \"C:/Users/user/anaconda3/envs/flower-ai-fixed/flowers-dataset\"\n",
    "\n",
    "# âœ… Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# âœ… Load datasets\n",
    "train_dataset = ImageFolder(root=os.path.join(dataset_path, \"train\"), transform=transform)\n",
    "val_dataset = ImageFolder(root=os.path.join(dataset_path, \"validation\"), transform=transform)\n",
    "test_dataset = ImageFolder(root=os.path.join(dataset_path, \"test\"), transform=transform)\n",
    "\n",
    "# âœ… Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# âœ… Load pre-trained ResNet18\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(512, 3)  # 3 flower classes\n",
    "model = model.to(device)\n",
    "\n",
    "# âœ… Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# âœ… Training Loop\n",
    "num_epochs = 10\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "    # âœ… Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_acc = correct / total\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    # âœ… Save the best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_flower_model.pth\")\n",
    "        print(\"âœ… Model Saved!\")\n",
    "\n",
    "# âœ… Testing\n",
    "model.load_state_dict(torch.load(\"best_flower_model.pth\"))\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_acc = correct / total\n",
    "print(f\"âœ… Final Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d811385-a7b4-4c2d-8241-4fd5c5c1db52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset sizes\n",
    "print(f\"Train Dataset: {len(train_dataset)} images\")\n",
    "print(f\"Validation Dataset: {len(val_dataset)} images\")\n",
    "print(f\"Test Dataset: {len(test_dataset)} images\")\n",
    "\n",
    "# Check class names\n",
    "print(f\"Classes: {train_dataset.classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ad77b15-7c0c-45f1-b66f-5f1ad0a50cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train Dataset Loaded: 1200 images\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  \n",
    "])\n",
    "\n",
    "# Define dataset path\n",
    "data_dir = r\"C:\\Users\\user\\anaconda3\\envs\\flower-ai-fixed\\flowers-dataset\"\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(root=f\"{data_dir}/train\", transform=transform)\n",
    "\n",
    "# Print to confirm\n",
    "print(f\"âœ… Train Dataset Loaded: {len(train_dataset)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f75dc5cb-138f-4c9b-b15d-cc7f0f81bd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DataLoader Loaded: 38 batches\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"âœ… DataLoader Loaded: {len(train_loader)} batches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44d0f355-3658-4ffc-9e4b-acb7cba56769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Size: 1200\n",
      "Batch Size: 32\n",
      "Total Batches: 38\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Dataset Size: {len(train_dataset)}\")\n",
    "print(f\"Batch Size: {train_loader.batch_size}\")\n",
    "print(f\"Total Batches: {len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5839d491-dd21-4369-84c2-c372c7aa12a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model Loaded and Modified!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load ResNet18\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# Modify the last layer to match your 3 classes\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 3)\n",
    "\n",
    "# Move model to CPU (since you donâ€™t have a GPU)\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(\"âœ… Model Loaded and Modified!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5415b62-c40d-40f2-ba20-aaa6f613915e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loss Function & Optimizer Defined!\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"âœ… Loss Function & Optimizer Defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392b24a-6a07-4da7-b9a4-a805cae2719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  \n",
    "        outputs = model(images)  \n",
    "        loss = criterion(outputs, labels)  \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"âœ… Training Completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f91280-6d92-4ccd-a464-5c1e36ad3c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total Training Batches: {len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e02c306-d2e2-40df-ab2a-6f569f72e635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train DataLoader Ready! Total Batches: 38\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define transformations for data augmentation & normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = datasets.ImageFolder(root=\"C:/Users/user/anaconda3/envs/flower-ai-fixed/flowers-dataset/train\", transform=transform)\n",
    "\n",
    "# Define DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"âœ… Train DataLoader Ready! Total Batches: {len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be9d7f24-bbfa-477d-ae87-fa67f748111a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Size: 1200\n",
      "Total Training Batches: 38\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Dataset Size: {len(train_dataset)}\")\n",
    "print(f\"Total Training Batches: {len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25f9c391-7d54-4d42-8ec4-8542167b434c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Device set to: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"âœ… Device set to:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bb6112a-91f9-4c45-b604-47ff3143c340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model defined and moved to device!\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# Load pre-trained ResNet18\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# Modify the final layer to match your number of classes (3 classes: daisy, rose, tulip)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, 3)\n",
    "\n",
    "# Move model to the correct device (CPU in your case)\n",
    "model.to(device)\n",
    "\n",
    "print(\"âœ… Model defined and moved to device!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0b8ae71-6ee9-47e7-b820-7a73178c7979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader Exists: True\n",
      "Train Dataset Exists: True\n",
      "Model Exists: True\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Loader Exists:\", 'train_loader' in globals())\n",
    "print(\"Train Dataset Exists:\", 'train_dataset' in globals())\n",
    "print(\"Model Exists:\", 'model' in globals())\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c36a0bb5-7103-4465-970e-0b4c26c4d175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model, optimizer, and loss function initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a simple CNN model\n",
    "class FlowerCNN(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(FlowerCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(16 * 64 * 64, num_classes)  # Adjust based on image size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten layer\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = FlowerCNN(num_classes=3)\n",
    "\n",
    "# Move model to CPU\n",
    "device = torch.device(\"cpu\")  \n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"âœ… Model, optimizer, and loss function initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0986e73-d53b-48d1-ab60-ed76e32581ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Exists: False\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Dataset Exists:\", 'train_dataset' in globals())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dd4b7d4-c2ba-4537-9db0-a97b530a4ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Exists: False\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Dataset Exists:\", 'train_dataset' in globals())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb52b376-52a3-47d5-8383-a2e900ed321b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Folder Exists: True\n",
      "Folders inside 'dataset': ['test', 'train']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Train Folder Exists:\", os.path.exists(\"dataset/train\"))\n",
    "print(\"Folders inside 'dataset':\", os.listdir(\"dataset\") if os.path.exists(\"dataset\") else \"No dataset folder found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "574bc0bc-0d65-4d1d-8c41-a5d71032cdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subfolders inside 'train': []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "train_path = \"dataset/train\"\n",
    "print(\"Subfolders inside 'train':\", os.listdir(train_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82cbdbc1-9321-41fa-9cf5-d6374e3e65b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset folder found!\n",
      "âœ… Subdirectories inside 'train': []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = \"dataset/train\"\n",
    "\n",
    "if os.path.exists(dataset_path):\n",
    "    print(\"âœ… Dataset folder found!\")\n",
    "    print(\"âœ… Subdirectories inside 'train':\", os.listdir(dataset_path))\n",
    "else:\n",
    "    print(\"âŒ Dataset folder not found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c37dccb-54d7-4998-9ed3-c276822ee202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Folder not found: dataset/train\\daisy\n",
      "âŒ Folder not found: dataset/train\\rose\n",
      "âŒ Folder not found: dataset/train\\tulip\n",
      "âœ… Image renaming completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = \"dataset/train\"\n",
    "\n",
    "# Function to rename images\n",
    "def rename_images(folder):\n",
    "    for idx, filename in enumerate(os.listdir(folder)):\n",
    "        old_path = os.path.join(folder, filename)\n",
    "        new_filename = f\"image_{idx+1}.jpg\"  # Renaming to image_1.jpg, image_2.jpg, etc.\n",
    "        new_path = os.path.join(folder, new_filename)\n",
    "\n",
    "        os.rename(old_path, new_path)\n",
    "        print(f\"Renamed: {old_path} â {new_path}\")\n",
    "\n",
    "# Rename images in each flower class folder\n",
    "for flower in [\"daisy\", \"rose\", \"tulip\"]:\n",
    "    folder_path = os.path.join(dataset_path, flower)\n",
    "    if os.path.exists(folder_path):\n",
    "        rename_images(folder_path)\n",
    "    else:\n",
    "        print(f\"âŒ Folder not found: {folder_path}\")\n",
    "\n",
    "print(\"âœ… Image renaming completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c74796b-ec19-4592-a602-069e5c5f1253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train folder exists.\n",
      "ğŸ“‚ Subfolders inside 'dataset/train': []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = \"dataset/train\"\n",
    "\n",
    "if os.path.exists(dataset_path):\n",
    "    print(\"âœ… Train folder exists.\")\n",
    "    print(\"ğŸ“‚ Subfolders inside 'dataset/train':\", os.listdir(dataset_path))\n",
    "else:\n",
    "    print(\"âŒ 'dataset/train' folder NOT found! Check your path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29ef9fcb-3003-421c-b88a-66035ee51a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Found folders in 'dataset': ['test', 'train']\n",
      "ğŸ“‚ Found folders in 'dataset\\test': []\n",
      "ğŸ“‚ Found folders in 'dataset\\train': []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = \"dataset\"\n",
    "\n",
    "# Recursively search for flower class folders\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    print(f\"ğŸ“‚ Found folders in '{root}': {dirs}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38867aa9-dc9e-4dc1-9851-48e7502b072d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Subfolders inside 'dataset/train': []\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“‚ Subfolders inside 'dataset/train':\", os.listdir(\"dataset/train\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb9e9f59-369d-4900-a896-87e8d58fd1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train folder exists.\n",
      "ğŸ“‚ Subfolders inside 'dataset/train': []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = \"dataset/train\"\n",
    "\n",
    "if os.path.exists(dataset_path):\n",
    "    print(\"âœ… Train folder exists.\")\n",
    "    print(\"ğŸ“‚ Subfolders inside 'dataset/train':\", os.listdir(dataset_path))\n",
    "else:\n",
    "    print(\"âŒ 'dataset/train' folder NOT found! Check your path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0dd12fd-5b78-4aca-ae59-3c799d49a483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Folder not found: dataset/train\\daisy\n",
      "âŒ Folder not found: dataset/train\\rose\n",
      "âŒ Folder not found: dataset/train\\tulip\n",
      "âœ… Image renaming completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = \"dataset/train\"\n",
    "\n",
    "# Function to rename images inside each class folder\n",
    "def rename_images(folder, prefix):\n",
    "    for idx, filename in enumerate(os.listdir(folder)):\n",
    "        old_path = os.path.join(folder, filename)\n",
    "        \n",
    "        # Ensure only image files are renamed\n",
    "        if os.path.isfile(old_path) and filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            new_filename = f\"{prefix}_{idx+1}.jpg\"  # e.g., daisy_1.jpg, rose_1.jpg, tulip_1.jpg\n",
    "            new_path = os.path.join(folder, new_filename)\n",
    "\n",
    "            os.rename(old_path, new_path)\n",
    "            print(f\"Renamed: {old_path} â {new_path}\")\n",
    "\n",
    "# Rename images for each flower class\n",
    "for flower in [\"daisy\", \"rose\", \"tulip\"]:\n",
    "    folder_path = os.path.join(dataset_path, flower)\n",
    "    if os.path.exists(folder_path):\n",
    "        rename_images(folder_path, flower)  # Use folder name as prefix\n",
    "    else:\n",
    "        print(f\"âŒ Folder not found: {folder_path}\")\n",
    "\n",
    "print(\"âœ… Image renaming completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "709365c3-899d-40ae-8eb8-4ae8889d9252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Folder not found: dataset/train\\daisy\n",
      "âŒ Folder not found: dataset/train\\rose\n",
      "âŒ Folder not found: dataset/train\\tulip\n",
      "âœ… Image renaming completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = \"dataset/train\"\n",
    "\n",
    "# Function to rename images inside each class folder\n",
    "def rename_images(folder, prefix):\n",
    "    for idx, filename in enumerate(os.listdir(folder)):\n",
    "        old_path = os.path.join(folder, filename)\n",
    "        \n",
    "        # Ensure only image files are renamed\n",
    "        if os.path.isfile(old_path) and filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            new_filename = f\"{prefix}_{idx+1}.jpg\"  # e.g., daisy_1.jpg, rose_1.jpg, tulip_1.jpg\n",
    "            new_path = os.path.join(folder, new_filename)\n",
    "\n",
    "            os.rename(old_path, new_path)\n",
    "            print(f\"Renamed: {old_path} â {new_path}\")\n",
    "\n",
    "# Rename images for each flower class\n",
    "for flower in [\"daisy\", \"rose\", \"tulip\"]:\n",
    "    folder_path = os.path.join(dataset_path, flower)\n",
    "    if os.path.exists(folder_path):\n",
    "        rename_images(folder_path, flower)  # Use folder name as prefix\n",
    "    else:\n",
    "        print(f\"âŒ Folder not found: {folder_path}\")\n",
    "\n",
    "print(\"âœ… Image renaming completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b9dd77-c3bc-4dbb-a4a7-80a5100b42cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 'train' folder exists.\n",
      "ğŸ“‚ Subfolders inside 'dataset/train': []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = \"dataset/train\"\n",
    "\n",
    "if os.path.exists(dataset_path):\n",
    "    print(\"âœ… 'train' folder exists.\")\n",
    "    print(\"ğŸ“‚ Subfolders inside 'dataset/train':\", os.listdir(dataset_path))\n",
    "else:\n",
    "    print(\"âŒ 'dataset/train' folder NOT found! Check your path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07edcc59-9da7-40af-9a3b-f66cfd7cdb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 'dataset' folder exists.\n",
      "ğŸ“‚ Subfolders inside 'dataset': ['test', 'train']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = \"dataset\"\n",
    "\n",
    "if os.path.exists(dataset_path):\n",
    "    print(\"âœ… 'dataset' folder exists.\")\n",
    "    print(\"ğŸ“‚ Subfolders inside 'dataset':\", os.listdir(dataset_path))\n",
    "else:\n",
    "    print(\"âŒ 'dataset' folder NOT found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59aba874-f2ee-4865-8488-5d9549ea0acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 'dataset' folder exists.\n",
      "ğŸ“‚ Subfolders inside 'dataset': ['test', 'train']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = \"dataset\"\n",
    "\n",
    "if os.path.exists(dataset_path):\n",
    "    print(\"âœ… 'dataset' folder exists.\")\n",
    "    print(\"ğŸ“‚ Subfolders inside 'dataset':\", os.listdir(dataset_path))\n",
    "else:\n",
    "    print(\"âŒ 'dataset' folder NOT found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aab6cf8-07cd-41d8-aed0-ae9408840711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Found in dataset: ['test', 'train']\n",
      "ğŸ“‚ Found in dataset\\test: []\n",
      "ğŸ“‚ Found in dataset\\train: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = \"dataset\"\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    print(f\"ğŸ“‚ Found in {root}: {dirs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50f3dba3-ac67-4d4b-947a-455eb47a2bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Found in dataset: ['test', 'train']\n",
      "ğŸ“‚ Found in dataset\\test: []\n",
      "ğŸ“‚ Found in dataset\\train: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = \"dataset\"\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    print(f\"ğŸ“‚ Found in {root}: {dirs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f797b8f9-b218-4b71-84a0-624ecaed1fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Found in dataset: ['test', 'train']\n",
      "ğŸ“‚ Found in dataset\\test: []\n",
      "ğŸ“‚ Found in dataset\\train: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = \"dataset\"\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    print(f\"ğŸ“‚ Found in {root}: {dirs}\")\n",
    "    if files:\n",
    "        print(f\"ğŸ“„ Files in {root}: {files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd633e3-a04f-49ac-bf2c-1aa1ee326621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
